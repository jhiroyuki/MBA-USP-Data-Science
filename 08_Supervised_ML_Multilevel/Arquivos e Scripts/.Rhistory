poisson_lambda1 <- function(m){
lambda <- 1
(exp(-lambda) * lambda ^ m) / factorial(m)
}
#Estabelecendo uma função da distribuição Poisson com lambda = 4
poisson_lambda4 <- function(m){
lambda <- 4
(exp(-lambda) * lambda ^ m) / factorial(m)
}
#Estabelecendo uma função da distribuição Poisson com lambda = 10
poisson_lambda10 <- function(m){
lambda <- 10
(exp(-lambda) * lambda ^ m) / factorial(m)
}
#Plotagem das funções estabelecidas anteriormente
data.frame(m = 0:20) %>%
ggplot(aes(x = m)) +
stat_function(fun = poisson_lambda1, size = 1.5,
aes(color = "01")) +
stat_function(fun = poisson_lambda4, size = 1.5,
aes(color = "04")) +
stat_function(fun = poisson_lambda10, size = 1.5,
aes(color = "10")) +
scale_color_viridis_d("Valores de" ~ lambda ~ "") +
labs(y = "Probabilidades", x = "m") +
theme_bw()
load(file = "corruption.RData")
glimpse(corruption) #Visualização das observações e das  especificações
#Estatísticas descritivas univariadas e tabela de frequências
summary(corruption)
load(file = "corruption.RData")
load(file = "corruption")
################################################################################
#               INSTALAÇÃO E CARREGAMENTO DE PACOTES NECESSÁRIOS               #
################################################################################
#Pacotes utilizados
pacotes <- c("plotly","tidyverse","reshape2","knitr","kableExtra","rgl",
"gghalves","ggdist","tidyquant","car","nlme","lmtest",
"fastDummies","msm","lmeInfo","jtools","gganimate","ggridges",
"viridis","hrbrthemes")
options(rgl.debug = TRUE)
if(sum(as.numeric(!pacotes %in% installed.packages())) != 0){
instalador <- pacotes[!pacotes %in% installed.packages()]
for(i in 1:length(instalador)) {
install.packages(instalador, dependencies = T)
break()}
sapply(pacotes, require, character = T)
} else {
sapply(pacotes, require, character = T)
}
stderr_nlme <- function(model){
if(base::class(model) != "lme"){
base::message("Use a lme object model from nlme package")
stop()}
resume <- base::summary(model)
if(base::length(base::names(model$groups))==1){
m.type <- "HLM2"
} else if(base::length(base::names(model$groups))==2){
m.type <- "HLM3"
}
if(m.type == "HLM2"){
vcov_matrix <- model$apVar
logs_sd_re <- base::attr(vcov_matrix,"Pars")
if(base::length(logs_sd_re)==2){
stderr_tau00 <- msm::deltamethod(~exp(x1)^2,logs_sd_re,vcov_matrix)
stderr_sigma <- msm::deltamethod(~exp(x2)^2,logs_sd_re,vcov_matrix)
results <- base::data.frame(`RE Components`=base::c("Var(v0j)","Var(e)"),
`Variance Estimatives`= base::c(base::exp(logs_sd_re)[[1]]^2,
base::exp(logs_sd_re[[2]])^2),
`Std Err.`=base::c(stderr_tau00,
stderr_sigma),
z=base::c(base::exp(logs_sd_re)[[1]]^2/stderr_tau00,
base::exp(logs_sd_re[[2]])^2/stderr_sigma),
`p-value`=base::round(stats::pnorm(q=base::c(base::exp(logs_sd_re)[[1]]^2/stderr_tau00,
base::exp(logs_sd_re[[2]])^2/stderr_sigma),
lower.tail=F)*2,3))
return(results)
}
else{
stderr_tau00 <- msm::deltamethod(~exp(x1)^2,logs_sd_re,vcov_matrix)
stderr_tau01 <- msm::deltamethod(~exp(x2)^2,logs_sd_re,vcov_matrix)
stderr_sigma <- msm::deltamethod(~exp(x4)^2,logs_sd_re,vcov_matrix)
results <- base::data.frame(Components=base::c("Var(v0j)","Var(v1j)","Var(e)"),
Estimatives= base::c(base::exp(logs_sd_re)[[1]]^2,
base::exp(logs_sd_re[[2]])^2,
base::exp(logs_sd_re[[4]])^2),
Std_Err=base::c(stderr_tau00,
stderr_tau01,
stderr_sigma),
z=base::c(base::exp(logs_sd_re)[[1]]^2/stderr_tau00,
base::exp(logs_sd_re[[2]])^2/stderr_tau01,
base::exp(logs_sd_re[[4]])^2/stderr_sigma),
`p-value`=base::round(stats::pnorm(q=base::c(base::exp(logs_sd_re)[[1]]^2/stderr_tau00,
base::exp(logs_sd_re[[2]])^2/stderr_tau01,
base::exp(logs_sd_re[[4]])^2/stderr_sigma),
lower.tail=F)*2,3))
return(results)
}
}
if(m.type == "HLM3"){
vcov_matrix <- model$apVar
logs_sd_re <-  base::attr(vcov_matrix,"Pars")
if(base::length(logs_sd_re) == 3){
stderr_tau_r000 <- msm::deltamethod(~exp(x1)^2,logs_sd_re,vcov_matrix)
stderr_tau_u000 <- msm::deltamethod(~exp(x2)^2,logs_sd_re,vcov_matrix)
stderr_sigma <- msm::deltamethod(~exp(x3)^2,logs_sd_re,vcov_matrix)
results <- base::data.frame(Components=base::c("Var(t00k)","Var(v0jk)","Var(e)"),
Estimatives=base::c(base::exp(logs_sd_re)[[2]]^2,
base::exp(logs_sd_re)[[1]]^2,
base::exp(logs_sd_re)[[3]]^2),
Std_Err=base::c(stderr_tau_u000,
stderr_tau_r000,
stderr_sigma),
z=base::c(base::exp(logs_sd_re)[[2]]^2/stderr_tau_u000,
base::exp(logs_sd_re)[[1]]^2/stderr_tau_r000,
base::exp(logs_sd_re)[[3]]^2/stderr_sigma),
`p-value`=base::round(stats::pnorm(q=base::c(base::exp(logs_sd_re)[[2]]^2/stderr_tau_u000,
base::exp(logs_sd_re)[[1]]^2/stderr_tau_r000,
base::exp(logs_sd_re)[[3]]^2/stderr_sigma),
lower.tail=F)*2,3))
return(results)
}
else{
stderr_tau_r000 <- msm::deltamethod(~exp(x1)^2,logs_sd_re,vcov_matrix)
stderr_tau_r100 <- msm::deltamethod(~exp(x2)^2,logs_sd_re,vcov_matrix)
stderr_tau_u000 <- msm::deltamethod(~exp(x4)^2,logs_sd_re,vcov_matrix)
stderr_tau_u100 <- msm::deltamethod(~exp(x5)^2,logs_sd_re,vcov_matrix)
stderr_sigma <- msm::deltamethod(~exp(x7)^2,logs_sd_re,vcov_matrix)
results <- base::data.frame(`RE_Components`=base::c("Var(t00k)","Var(t10k)",
"Var(v0jk)","Var(v1jk)",
"Var(e)"),
`Variance Estimatives`=base::c(base::exp(logs_sd_re)[[4]]^2,
base::exp(logs_sd_re)[[5]]^2,
base::exp(logs_sd_re)[[1]]^2,
base::exp(logs_sd_re)[[2]]^2,
base::exp(logs_sd_re)[[7]]^2),
`Std Err.`=base::c(stderr_tau_u000,
stderr_tau_u100,
stderr_tau_r000,
stderr_tau_r100,
stderr_sigma),
z=base::c(base::exp(logs_sd_re)[[4]]^2/stderr_tau_u000,
base::exp(logs_sd_re)[[5]]^2/stderr_tau_u100,
base::exp(logs_sd_re)[[1]]^2/stderr_tau_r000,
base::exp(logs_sd_re)[[2]]^2/stderr_tau_r100,
base::exp(logs_sd_re)[[7]]^2/stderr_sigma),
`p-value`=base::round(stats::pnorm(q=base::c(base::exp(logs_sd_re)[[4]]^2/stderr_tau_u000,
base::exp(logs_sd_re)[[5]]^2/stderr_tau_u100,
base::exp(logs_sd_re)[[1]]^2/stderr_tau_r000,
base::exp(logs_sd_re)[[2]]^2/stderr_tau_r100,
base::exp(logs_sd_re)[[7]]^2/stderr_sigma),
lower.tail=F)*2,3))
return(results)
}
}
}
#Carregamento da base de dados
load(file = "estudante_escola.RData")
#Visualização da base de dados
estudante_escola %>%
kable() %>%
kable_styling(bootstrap_options = "striped",
full_width = F,
font_size = 25)
#Estatísticas descritivas
summary(estudante_escola)
#Estudo sobre o desbalanceamento dos dados
estudante_escola %>%
group_by(escola) %>%
summarise(quantidade = n()) %>%
kable() %>%
kable_styling(bootstrap_options = "striped",
full_width = F,
font_size = 25)
#Desempenho médio dos estudantes por escola
estudante_escola %>%
group_by(escola) %>%
summarise(`desempenho médio` = mean(desempenho, na.rm = T)) %>%
kable() %>%
kable_styling(bootstrap_options = "striped",
full_width = F,
font_size = 25)
#Exploração visual do desempenho médio
estudante_escola %>%
group_by(escola) %>%
mutate(desempenho_medio = mean(desempenho, na.rm = TRUE)) %>%
ggplot() +
geom_point(aes(x = escola, y = desempenho),color = "orange", alpha = 0.5, size = 4) +
geom_line(aes(x = escola, y = desempenho_medio,
group = 1, color = "Desempenho Escolar Médio"), size = 1.5) +
scale_colour_viridis_d() +
labs(x = "Escola",
y = "Desempenho Escolar") +
theme(legend.title = element_blank(),
panel.border = element_rect(NA),
panel.grid = element_line("grey"),
panel.background = element_rect("white"),
legend.position = "bottom",
axis.text.x = element_text(angle = 90))
#Boxplot da variável dependente (desempenho)
ggplotly(
ggplot(estudante_escola, aes(x = "", y = desempenho)) +
geom_boxplot(fill = "deepskyblue",    # cor da caixa
alpha = 0.7,             # transparência
color = "black",         # cor da borda
outlier.colour = "red",  # cor dos outliers
outlier.shape = 15,      # formato dos marcadores dos outliers
outlier.size = 2.5) +    # tamanho dos marcadores dos outliers
geom_jitter(width = 0.1, alpha = 0.5, size = 1.3, color = "darkorchid") +
labs(y = "Desempenho") +
theme(panel.background = element_rect("white"),
panel.grid = element_line("grey95"),
panel.border = element_rect(NA),
legend.position="none",
plot.title = element_text(size=15)) +
ggtitle("Boxplot da variável 'desempenho'") +
xlab("")
)
#Kernel density estimation (KDE) - função densidade de probabilidade da
#variável dependente (desempenho), com histograma
ggplotly(
ggplot(estudante_escola, aes(x = desempenho)) +
geom_density(aes(x = desempenho),
position = "identity", color = "black", size = 1) +
geom_histogram(aes(y = ..density..), color = "white", fill = "deepskyblue",
bins = 30) +
theme_classic()
)
#Boxplot da variável dependente (desempenho) por escola
ggplotly(
ggplot(estudante_escola, aes(x = escola,y = desempenho)) +
geom_boxplot(aes(fill = escola, alpha = 0.7)) +
geom_jitter(width = 0.1, alpha = 0.5, size = 1.3, color = "darkorchid") +
scale_fill_viridis_d() +
labs(y = "Desempenho") +
theme_classic() +
ggtitle("Boxplots da variável 'desempenho' para as escolas")
)
#Boxplot alternativo da variável dependente (desempenho) por escola
#pacote 'gghalves'
estudante_escola %>%
ggplot(aes(escola, desempenho, fill = escola)) +
geom_half_boxplot(
outlier.colour = "red"
) +
geom_half_dotplot(
aes(fill = escola),
dotsize = 0.75,
alpha = 0.5,
stackratio = 0.45,
color = "black"
) +
scale_fill_viridis_d() +
theme_tq() +
labs(title = "Boxplots da variável 'desempenho' para as escolas")
#Distribuições da variável 'desempenho' para as escolas, com boxplots
#pacote 'ggdist'
estudante_escola %>%
ggplot(aes(x = escola, y = desempenho, fill = escola)) +
ggdist::stat_halfeye(
adjust = 0.5,
justification = -.2,
.width = 0,
point_colour = NA
) +
geom_boxplot(
width = .12,
outlier.color = NA,
alpha = 0.5
) +
ggdist::stat_dots(
side = "left",
justification = 1.1,
binwidth = .25
) +
scale_fill_viridis_d() +
theme_tq() +
labs(
title = "Distribuições da variável 'desempenho' para as escolas",
subtitle = "com boxplots",
x = "Escola",
y = "Desempenho") +
coord_flip()
#Gráfico alternativo com distribuições da variável 'desempenho' para as escolas
#função 'geom_density_ridges_gradient' do pacote 'ggridges'
ggplot(estudante_escola, aes(x = desempenho, y = escola, fill = ..x..)) +
geom_density_ridges_gradient(scale = 3, rel_min_height = 0.01) +
scale_fill_viridis(name = "Desempenho", option = "turbo", direction = -1) +
labs(
title = "Distribuições da variável 'desempenho' para as escolas",
x = "Desempenho",
y = "Escola") +
theme_ipsum() +
theme(
legend.position="none",
panel.spacing = unit(0.1, "lines"),
strip.text.x = element_text(size = 5)
)
#Kernel density estimation (KDE) - função densidade de probabilidade da
#variável dependente (desempenho) por escola
ggplotly(
ggplot(estudante_escola, aes(x = desempenho)) +
geom_density(aes(color = escola, fill = escola),
position = "identity", alpha = 0.3) +
scale_color_viridis_d() +
scale_fill_viridis_d() +
theme_classic()
)
#Kernel density estimation (KDE) - função densidade de probabilidade da
#variável dependente (desempenho), com histograma e por escola separadamente
#(função facet_wrap)
estudante_escola %>%
group_by(escola) %>%
mutate(linhas = 1:n()) %>%
mutate(x = unlist(density(desempenho, n = max(linhas))["x"]),
y = unlist(density(desempenho, n = max(linhas))["y"])) %>%
ggplot() +
geom_area(aes(x = x, y = y, group = escola, fill = escola), color = "black", alpha = 0.3) +
geom_histogram(aes(x = desempenho, y = ..density.., fill = escola),
color = "black", position = 'identity', alpha = 0.1) +
facet_wrap(~ escola) +
scale_fill_viridis_d() +
scale_color_viridis_d() +
theme_bw()
#Gráfico de desempenho x horas (OLS)
ggplotly(
estudante_escola %>%
ggplot(aes(x = horas, y = desempenho)) +
geom_smooth(method = "lm", formula = y ~ x, se = F) +
geom_point() +
scale_colour_viridis_d() +
labs(x = "Quantidade Semanal de Horas de Estudo do Aluno",
y = "Desempenho Escolar") +
theme_bw()
)
#Gráfico de desempenho x horas (OLS) por escola separadamente
#(funções transition_states e animate do pacote gganimate)
ggplot(estudante_escola, aes(x=horas, y=desempenho, color=escola)) +
geom_point() +
geom_smooth(method = "lm", formula = y ~ x, se = F) +
transition_states(escola, transition_length = 1, state_length = 2) +
enter_fade() +
exit_shrink() +
ease_aes('linear') +
labs(x = "Quantidade Semanal de Horas de Estudo do Aluno",
y = "Desempenho Escolar") +
scale_color_viridis_d() +
ggtitle("Desempenho escolar por escola", subtitle = "Escola: {closest_state}") +
theme_minimal() -> p
#Gráfico de desempenho x horas por escola (visualização do contexto)
#NOTE QUE A PERSPECTIVA MULTINÍVEL NATURALMENTE CONSIDERA O COMPORTAMENTO
#HETEROCEDÁSTICO NOS DADOS!
ggplotly(
estudante_escola %>%
ggplot(aes(x = horas, y = desempenho, color = escola)) +
geom_smooth(method = "lm", formula = y ~ x, se = F) +
geom_point() +
guides(color = "none") +
scale_colour_viridis_d() +
labs(x = "Quantidade Semanal de Horas de Estudo do Aluno",
y = "Desempenho Escolar") +
theme_bw()
)
#O gráfico a seguir apresenta uma plotagem sob a perspectiva de um modelo
#com equação única (ex.: OLS)
base_exemplo <- estudante_escola %>%
filter(escola %in% c("1","2","3","4","5","6")) %>%
mutate(escola = as.numeric(escola))
scatter3d(desempenho ~ horas + escola, #função scatter3d do pacote car
data = base_exemplo,
fit = "linear")
#Agora plotamos o mesmo gráfico, porém de forma tridimensional,
#considerando modelos distintos para as diferentes escolas. Plotamos
#apenas as 06 primeiras escolas em razão de uma limitação do algoritmo
scatter3d(desempenho ~ horas + escola,
groups = factor(base_exemplo$escola),
data = base_exemplo,
fit = "linear",
surface = T)
#Estimação do modelo nulo (função lme do pacote nlme)
modelo_nulo_hlm2 <- lme(fixed = desempenho ~ 1,
random = ~ 1 | escola,
data = estudante_escola,
method = "REML") #restricted estimation of maximum likelihood (Gelman)
#Parâmetros do modelo
summary(modelo_nulo_hlm2)
#Verificando a funcionalidade da função 'stderr_nlme' desenvolvida
stderr_nlme(modelo_nulo_hlm2)
#Parâmetros do modelo
summary(modelo_nulo_hlm2)
#Verificando a funcionalidade da função 'stderr_nlme' desenvolvida
stderr_nlme(modelo_nulo_hlm2)
modelo_nulo_hlm2.resid
modelo_nulo_hlm2.residuals
modelo_nulo_hlm2.residual
resid(modelo_nulo_hlm2)
var(resid(modelo_nulo_hlm2))
#Estimação do modelo nulo (função lme do pacote nlme)
modelo_nulo_hlm2 <- lme(fixed = desempenho ~ 1,
random = ~ 1 | escola,
data = estudante_escola,
method = "REML") #restricted estimation of maximum likelihood (Gelman)
#Parâmetros do modelo
summary(modelo_nulo_hlm2)
#Verificando a funcionalidade da função 'stderr_nlme' desenvolvida
stderr_nlme(modelo_nulo_hlm2)
var(resid(modelo_nulo_hlm2)
var(resid(modelo_nulo_hlm2))
var(resid(modelo_nulo_hlm2))
################################################################################
#                    COMPARAÇÃO DO HLM2 NULO COM UM OLS NULO                   #
################################################################################
#Para estimarmos o modelo OLS nulo, podemos comandar o seguinte
modelo_ols_nulo <- lm(formula = desempenho ~ 1,
data = estudante_escola)
var(resid(modelo_nulo_hlm2))
var(resid(modelo_nulo_hlm2))
#Parâmetros do modelo
summary(modelo_nulo_hlm2)
#Verificando a funcionalidade da função 'stderr_nlme' desenvolvida
stderr_nlme(modelo_nulo_hlm2)
var(resid(modelo_nulo_hlm2))
#Parâmetros do modelo
summary(modelo_nulo_hlm2)
var(resid(modelo_nulo_hlm2))
#Verificando a funcionalidade da função 'stderr_nlme' desenvolvida
stderr_nlme(modelo_nulo_hlm2)
vcov_matrix <- modelo_nulo_hlm2$apVar
View(vcov_matrix)
modelo_nulo_hlm2$subset
modelo_nulo_hlm2$weights
modelo_nulo_hlm2$resid
modelo_nulo_hlm2$apVar
names(modelo_nulo_hlm2)
modelo_nulo_hlm2$sigma
modelo_nulo_hlm2$apVar
#Parâmetros do modelo
summary(modelo_nulo_hlm2)
#Verificando a funcionalidade da função 'stderr_nlme' desenvolvida
stderr_nlme(modelo_nulo_hlm2)
modelo_nulo_hlm2$apVar
modelo_nulo_hlm2$apVar[1]
modelo_nulo_hlm2$apVar[2]
modelo_nulo_hlm2$apVar[3]
modelo_nulo_hlm2$apVar[4]
modelo_nulo_hlm2$apVar[5]
modelo_nulo_hlm2$apVar[6]
modelo_nulo_hlm2$apVar[10]
View(p)
View(vcov_matrix)
modelo_nulo_hlm2$apVar
modelo_nulo_hlm2$varFix
modelo_nulo_hlm2$terms
modelo_nulo_hlm2$coeff
modelo_nulo_hlm2$apVar
exp(modelo_nulo_hlm2$apVar)
#Parâmetros do modelo
summary(modelo_intercept_hlm2)
#Estimação do modelo com Interceptos Aleatórios
modelo_intercept_hlm2 <- lme(fixed = desempenho ~ horas,
random = ~ 1 | escola,
data = estudante_escola,
method = "REML")
#Estimação do modelo nulo (função lme do pacote nlme)
modelo_nulo_hlm2 <- lme(fixed = desempenho ~ 1,
random = ~ 1 | escola,
data = estudante_escola,
method = "REML") #restricted estimation of maximum likelihood (Gelman)
#Parâmetros do modelo
summary(modelo_nulo_hlm2)
#Verificando a funcionalidade da função 'stderr_nlme' desenvolvida
stderr_nlme(modelo_nulo_hlm2)
#Verificando a funcionalidade da função 'stderr_nlme' desenvolvida
stderr_nlme(modelo_nulo_hlm2)
#Estimação do modelo nulo (função lme do pacote nlme)
modelo_nulo_hlm2 <- lme(fixed = desempenho ~ 1,
random = ~ 1 | escola,
data = estudante_escola,
method = "REML") #restricted estimation of maximum likelihood (Gelman)
#Parâmetros do modelo
summary(modelo_nulo_hlm2)
#Verificando a funcionalidade da função 'stderr_nlme' desenvolvida
stderr_nlme(modelo_nulo_hlm2)
var(resid(modelo_nulo_hlm2))
base::attr(vcov_matrix,"Pars")
modelo_nulo_hlm2$apVar
msm::deltamethod(~exp(x1)^2,logs_sd_re,vcov_matrix)
logs_sd_re <- base::attr(vcov_matrix,"Pars")
msm::deltamethod(~exp(x1)^2,logs_sd_re,vcov_matrix)
exp(logs_sd_re)[[1]]^2,
exp(logs_sd_re)[[1]]^2
exp(logs_sd_re)[[2]]^2
modelo_nulo_hlm2$apVar
results <- base::data.frame(`RE Components`=base::c("Var(v0j)","Var(e)"),
`Variance Estimatives`= base::c(base::exp(logs_sd_re)[[1]]^2,
base::exp(logs_sd_re[[2]])^2),
`Std Err.`=base::c(stderr_tau00,
stderr_sigma),
z=base::c(base::exp(logs_sd_re)[[1]]^2/stderr_tau00,
base::exp(logs_sd_re[[2]])^2/stderr_sigma),
`p-value`=base::round(stats::pnorm(q=base::c(base::exp(logs_sd_re)[[1]]^2/stderr_tau00,
base::exp(logs_sd_re[[2]])^2/stderr_sigma),
lower.tail=F)*2,3))
#Estimação do modelo nulo (função lme do pacote nlme)
modelo_nulo_hlm2 <- lme(fixed = desempenho ~ 1,
random = ~ 1 | escola,
data = estudante_escola,
method = "REML") #restricted estimation of maximum likelihood (Gelman)
#Parâmetros do modelo
summary(modelo_nulo_hlm2)
#Verificando a funcionalidade da função 'stderr_nlme' desenvolvida
stderr_nlme(modelo_nulo_hlm2)
