CurvaROC
# Vamos calcular a área da curva ROC com uma função no Caret
# A função é o twoClassSummary, que espera como entrada um dataframe com esse layout:
# obs: uma coluna contendo um fator com as classes observadas
# pred: fator com as classes preditas
# <classe 1> (Y no caso): contém a probabilidade da classe 1
# <classe 2> (Y no caso): contém a probabilidade da classe 2
aval_teste <- data.frame(obs=teste$Survived,
pred=c_teste,
Y = p_teste[,2],
N = 1-p_teste[,2]
)
twoClassSummary(aval_teste, lev=levels(aval_teste$obs))
# Podemos usar o mesmo dataframe para fazer a curva ROC:
CurvaROC <- ggplot(aval_teste, aes(d = obs, m = Y, colour='a')) +
plotROC::geom_roc(n.cuts = 0) +
scale_color_viridis_d(direction = -1, begin=0, end=.25) +
theme(legend.position = "none") +
ggtitle("Curva ROC - base de teste")
CurvaROC
p_treino = stats::predict(arvore_poda, treino)
c_treino = base::factor(ifelse(p_treino[,2]>.5, "Y", "N"))
p_teste = stats::predict(arvore_poda, teste)
c_teste = base::factor(ifelse(p_teste[,2]>.5, "Y", "N"))
#####
aval_treino <- data.frame(obs=treino$inadimplencia,
pred=c_treino,
Y = p_treino[,2],
N = 1-p_treino[,2]
)
caret::twoClassSummary(aval_treino, lev=levels(aval_treino$obs))
# Podemos usar o mesmo dataframe para fazer a curva ROC:
CurvaROC <- ggplot2::ggplot(aval_treino, aes(d = obs, m = Y, colour='1')) +
plotROC::geom_roc(n.cuts = 0) +
scale_color_viridis_d(direction = -1, begin=0, end=.25) +
theme(legend.position = "none") +
ggtitle("Curva ROC - base de treino")
CurvaROC
# Vamos calcular a área da curva ROC com uma função no Caret
# A função é o twoClassSummary, que espera como entrada um dataframe com esse layout:
# obs: uma coluna contendo um fator com as classes observadas
# pred: fator com as classes preditas
# <classe 1> (Y no caso): contém a probabilidade da classe 1
# <classe 2> (Y no caso): contém a probabilidade da classe 2
aval_teste <- data.frame(obs=teste$Survived,
pred=c_teste,
Y = p_teste[,2],
N = 1-p_teste[,2]
)
# Vamos calcular a área da curva ROC com uma função no Caret
# A função é o twoClassSummary, que espera como entrada um dataframe com esse layout:
# obs: uma coluna contendo um fator com as classes observadas
# pred: fator com as classes preditas
# <classe 1> (Y no caso): contém a probabilidade da classe 1
# <classe 2> (Y no caso): contém a probabilidade da classe 2
aval_teste <- data.frame(obs=teste$inadimplencia,
pred=c_teste,
Y = p_teste[,2],
N = 1-p_teste[,2]
)
twoClassSummary(aval_teste, lev=levels(aval_teste$obs))
# Podemos usar o mesmo dataframe para fazer a curva ROC:
CurvaROC <- ggplot(aval_teste, aes(d = obs, m = Y, colour='a')) +
plotROC::geom_roc(n.cuts = 0) +
scale_color_viridis_d(direction = -1, begin=0, end=.25) +
theme(legend.position = "none") +
ggtitle("Curva ROC - base de teste")
CurvaROC
twoClassSummary(aval_teste, lev=levels(aval_teste$obs))
teste$score <- p_teste[,2]
teste$score_cat <- qcut(teste$score, 5)
teste$score_cat <- quantcut(teste$score, 5)
teste$score <- p_teste[,2]
teste$score_cat <- quantcut(teste$score, 5)
descritiva2("score_cat", "inadimplencia", teste)
teste$inad <- as.integer(teste$inadimplencia)
teste$inad <- as.integer(teste$inadimplencia)
teste$score <- p_teste[,2]
teste$score_cat <- quantcut(teste$score, 5)
descritiva2("idade_cat", "inad", teste)
descritiva("idade_cat", "inad", teste)
########################
# Instalação de pacotes
pacotes <- c(
'tidyverse',  # Pacote básico de datawrangling
'rpart',      # Biblioteca de árvores
'rpart.plot', # Conjunto com Rpart, plota a parvore
'gtools',     # funções auxiliares como quantcut,
'Rmisc',      # carrega a função sumarySE para a descritiva
'scales',     # importa paletas de cores
'viridis',    # Escalas 'viridis' para o ggplot2
'caret',       # Funções úteis para machine learning
'AMR',
'randomForest',
'fastDummies',
'rattle',
'xgboost',
'ggpubr'
)
if(sum(as.numeric(!pacotes %in% installed.packages())) != 0){
instalador <- pacotes[!pacotes %in% installed.packages()]
for(i in 1:length(instalador)) {
install.packages(instalador, dependencies = T)
break()}
sapply(pacotes, require, character = T)
} else {
sapply(pacotes, require, character = T)
}
#####
# Gerando os dados
# x é uma sequencia de valores entre 0 e 1
set.seed(2360873)
x <- seq(0,1, length.out=1000)
# y segue uma relação quadrática
a <- 0
b <- 10
c <- -10
y <- a + b*x + c*x**2 + rnorm(length(x), mean=0, sd=.1)
df <- data.frame(x, y)
p0 <- ggplot(df, aes(x,y)) +
geom_point(aes(colour='Observado')) +
scale_color_viridis(discrete=TRUE, begin=0, end=.85, name = "Valor") +
theme(legend.position="bottom",
legend.spacing.x = unit(0, 'cm'))
p0
data(tips)
library("reshape2")
data(tips)
tips %>% head
data(reshape2::tips)
#####
# Gerando os dados
# x é uma sequencia de valores entre 0 e 1
set.seed(2360873)
x <- seq(0,1, length.out=1000)
# y segue uma relação quadrática
a <- 0
b <- 10
c <- -10
y <- a + b*x + c*x**2 + rnorm(length(x), mean=0, sd=.1)
df <- data.frame(x, y)
p0 <- ggplot(df, aes(x,y)) +
geom_point(aes(colour='Observado')) +
scale_color_viridis(discrete=TRUE, begin=0, end=.85, name = "Valor") +
theme(legend.position="bottom",
legend.spacing.x = unit(0, 'cm'))
p0
########################
# Construindo a árvore #
tree <- rpart(y~x,
data=df,
control=rpart.control(maxdepth = 5, cp=0))
# Plotando a árvore
paleta = scales::viridis_pal(begin=.75, end=1)(20)
rpart.plot::rpart.plot(tree,
box.palette = paleta) # Paleta de cores
########################
# Construindo a árvore #
tree <- rpart(y~x,
data=df,
control=rpart.control(maxdepth = 3, cp=0))
########################
# Construindo a árvore #
tree <- rpart(y~x,
data=df,
control=rpart.control(maxdepth = 3, cp=0))
# Plotando a árvore
paleta = scales::viridis_pal(begin=.75, end=1)(20)
rpart.plot::rpart.plot(tree,
box.palette = paleta) # Paleta de cores
# Valores preditos
df['p'] = predict(tree, df)
df$p %>% tail # investigar a previsão
df['r'] = df$y - df$p
# Valores esperados e observados
boost0_O_vs_E <- ggplot(df, aes(x,y)) +
geom_point(alpha=.7, size=.5, aes(colour='Observado')) +
geom_path(aes(x,p, colour='Esperado')) + #Ploting
scale_color_viridis(discrete=TRUE, begin=0, end=.8, name = "Dado: ") +
theme_bw() +
theme(legend.position="bottom") +
# guides(colour = guide_legend(label.position = "bottom")) +
labs(title="Valores observados vs esperados") +
scale_y_continuous(name= "y") +
scale_x_continuous(name= "x")
# Valores esperados e observados
boost0_O_vs_E <- ggplot(df, aes(x,y)) +
geom_point(alpha=.7, size=.5, aes(colour='Observado')) +
geom_path(aes(x,p, colour='Esperado')) + #Ploting
scale_color_viridis(discrete=TRUE, begin=0, end=.8, name = "Dado: ") +
theme_bw() +
theme(legend.position="bottom") +
# guides(colour = guide_legend(label.position = "bottom")) +
labs(title="Valores observados vs esperados") +
scale_y_continuous(name= "y") +
scale_x_continuous(name= "x")
boost0_O_vs_E
########################
# Construindo a árvore #
tree <- rpart(y~x,
data=df,
control=rpart.control(maxdepth = 2, cp=0))
# Plotando a árvore
paleta = scales::viridis_pal(begin=.75, end=1)(20)
rpart.plot::rpart.plot(tree,
box.palette = paleta) # Paleta de cores
# Valores preditos
df['p'] = predict(tree, df)
df$p %>% tail # investigar a previsão
df['r'] = df$y - df$p
# Valores esperados e observados
boost0_O_vs_E <- ggplot(df, aes(x,y)) +
geom_point(alpha=.7, size=.5, aes(colour='Observado')) +
geom_path(aes(x,p, colour='Esperado')) + #Ploting
scale_color_viridis(discrete=TRUE, begin=0, end=.8, name = "Dado: ") +
theme_bw() +
theme(legend.position="bottom") +
# guides(colour = guide_legend(label.position = "bottom")) +
labs(title="Valores observados vs esperados") +
scale_y_continuous(name= "y") +
scale_x_continuous(name= "x")
boost0_O_vs_E
# Gráfico de resíduos
boost0_res <- ggplot(df, aes(x,r)) +
geom_point(alpha=.7, size=.5, aes(colour='Resíduo')) +
scale_color_viridis(discrete=TRUE, begin=0, end=.8, name = "Dado: ") +
theme_bw() +
theme(legend.position="bottom") +
labs(title="Gráfico de resíduos") +
scale_y_continuous(name= "r") +
scale_x_continuous(name= "x")
boost0_res
# painel com os dois gráficos
ggpubr::ggarrange(boost0_O_vs_E, boost0_res,
# labels = c("A", "B"),
ncol = 2, nrow = 1)
# Gerando os dados
set.seed(2360873)
L=1000
dados = rnorm(L)**2
# o quantil amostral é:
quantile(dados, .75)
dados
dados = 80 + rnorm(L)*2
dados
hist(dados)
call <- max(0; dados)
call <- pmax(80; dados)
call <- pmax(80, dados)
call
call <- pmax(0, dados-80)
call
call >%> head(dados >%> head)
dados >%> head
call >%> head
call[:10]
call[1:10]
dados[1:10]
# Gerando os dados
set.seed(2360873)
L=1
dados = 80 + rnorm(L)*2
# Gerando os dados
set.seed(2360873)
L=1
dados = 82 + rnorm(L)*2
hist(dados)
call <- pmax(0, dados-80)
# Gerando os dados
set.seed(2360873)
L=1
dados = 82 + rnorm(L)*2
dados
L=10000
dados = 82 + rnorm(L)*2
dados
hist(dados)
dados >%> head
hist(dados)
dados[1:10]
hist(dados)
call <- pmax(0, dados-80)
call[1:10]
dados[1:10]
# o quantil amostral é:
quantile(call, .99)
# Buscar reprodutibilidade
set.seed(2360873)
# Gera 80% de 1´s e 20% de 2´s para separar as amostras
n <- sample(1:2, # vamos amostrar elementos do conjunto c(1,2)
size=nrow(titanic), # O tamanho da amostragem é 891
replace=TRUE, # Amostragem com reposição (de c(1,2))
prob=c(0.8,0.2)) # A probabilidade de ser 1 é 80%, de ser 2 é 20%
# Amostra de treino: n==1 (os 80%)
treino <- titanic[n==1,]
# Amostra de teste: n==2 (os 20%)
teste <- titanic[n==2,]
# Semente aleatória para buscar a reprodutibilidade
set.seed(2360873)
# medir tempo de execução (iniciar o cronometro)
start_time <- Sys.time()
# Rodar o algoritmo
treino_rf <- randomForest::randomForest(
Survived ~ .,
data = treino,
ntree = 50,
mtry = 3,
importance = T)
# parar o cronometro
end_time <- Sys.time()
end_time - start_time
# Base de treino
avalia <- function(modelo, nome_modelo="modelo"){
p_treino <- predict(modelo, treino, type='prob') # Probabilidade predita
c_treino <- predict(modelo, treino)              # Classificação
#Base de teste
p_teste <- predict(modelo, teste, type='prob')
c_teste <- predict(modelo, teste)
# Data frame de avaliação (Treino)
aval_treino <- data.frame(obs=treino$Survived,
pred=c_treino,
Y = p_treino[,2],
N = 1-p_treino[,2]
)
# Data frame de avaliação (Teste)
aval_teste <- data.frame(obs=teste$Survived,
pred=c_teste,
Y = p_teste[,2],
N = 1-p_teste[,2]
)
tcs_treino <- caret::twoClassSummary(aval_treino,
lev=levels(aval_treino$obs))
tcs_teste <- caret::twoClassSummary(aval_teste,
lev=levels(aval_teste$obs))
##########################
# Curva ROC              #
CurvaROC <- ggplot2::ggplot(aval_teste, aes(d = obs, m = Y, colour='1')) +
plotROC::geom_roc(n.cuts = 0, color="blue") +
plotROC::geom_roc(data=aval_treino,
aes(d = obs, m = Y, colour='1'),
n.cuts = 0, color = "red") +
scale_color_viridis_d(direction = -1, begin=0, end=.25) +
theme(legend.position = "none") +
ggtitle(paste("Curva ROC | ", nome_modelo, " | AUC-treino=",
percent(tcs_treino[1]),
"| AUC_teste = ",
percent(tcs_teste[1]))
)
print('Avaliação base de treino')
print(tcs_treino)
print('Avaliação base de teste')
print(tcs_teste)
CurvaROC
}
avalia(treino_rf, nome_modelo="Random Forest")
tempo_ini <- Sys.time()
# O objeto gerado por trainControl vai controlar o algoritmo
controle <- caret::trainControl(
method='repeatedcv', # Solicita um K-Fold com repetições
number=4, # Número de FOLDS (o k do k-fold)
repeats=2, # Número de repetições
search='grid', # especifica o grid-search
summaryFunction = twoClassSummary, # Função de avaliação de performance
classProbs = TRUE # Necessário para calcular a curva ROC
)
# agora vamos especificar o grid
grid <- base::expand.grid(.mtry=c(1:10))
# Vamos treinar todos os modelos do grid-search com cross-validation
gridsearch_rf <- caret::train(Survived ~ .,         # Fórmula (todas as variáveis)
data = treino,       # Base de dados
method = 'rf',        # Random-forest
metric='ROC',         # Escolhe o melhor por essa métrica
trControl = controle, # Parâmetros de controle do algoritmo
ntree=100,            # Numero de árvores
tuneGrid = grid)      # Percorre o grid especificado aqui
print(gridsearch_rf)
plot(gridsearch_rf)
tempo_fim <- Sys.time()
tempo_fim - tempo_ini
avalia(gridsearch_rf, nome_modelo='RF Tunado')
########################
# Instalação de pacotes
pacotes <- c(
'tidyverse',  # Pacote básico de datawrangling
'rpart',      # Biblioteca de árvores
'rpart.plot', # Conjunto com Rpart, plota a parvore
'gtools',     # funções auxiliares como quantcut,
'Rmisc',      # carrega a função sumarySE para a descritiva
'scales',     # importa paletas de cores
'viridis',    # Escalas 'viridis' para o ggplot2
'caret',       # Funções úteis para machine learning
'AMR',
'randomForest',
'fastDummies',
'rattle',
'xgboost',
'ggpubr'
)
if(sum(as.numeric(!pacotes %in% installed.packages())) != 0){
instalador <- pacotes[!pacotes %in% installed.packages()]
for(i in 1:length(instalador)) {
install.packages(instalador, dependencies = T)
break()}
sapply(pacotes, require, character = T)
} else {
sapply(pacotes, require, character = T)
}
########################## Funções de apoio ####################################
descritiva <- function(var){
# Sumariza a taxa de sobreviventes por categoria da variável em análise
tgc <- Rmisc::summarySE(tmp, measurevar="survived", groupvars=c(var))
ggplot(tgc) +
# Plota o gráfico de barras com as frequências
geom_bar(aes(x=tgc[,var], weight=N/891, fill=as.factor(tgc[,var]))) +
# Plota as barras de erro
geom_errorbar(aes(x=tgc[,var], y=survived, ymin=survived-se, ymax=survived+se, colour='1'), width=.1) +
# Plota as médias de cada grupo
geom_point(aes(x=tgc[,var], y=survived, colour='1', group='1')) +
# Plota as linhas que conectam as médias
geom_line(aes(x=tgc[,var], y=survived, colour='1', group='1')) +
# Escala de cores do gráfico de médias
scale_color_viridis_d(direction = -1, begin=0, end=.25) +
# Escala de cores do gráfico de barras
scale_fill_viridis_d(direction = -1, begin=.85, end=.95) +
# Estética mais 'leve' do gráfico
theme(panel.background = element_rect(fill = "white", colour = "grey", linetype = "solid"),
panel.grid.major = element_line(size = 0.15, linetype = 'solid', colour = "grey")) +
# Remove a legenda
theme(legend.position = "none") +
# Rótulo dos eixos
xlab(var) + ylab("Taxa de sobreviventes") +
# Marcas do eixo secundário
scale_y_continuous(sec.axis = sec_axis(~.*891, name = "Frequencia"), labels = scales::percent)
}
descritiva2 <- function(var, resp, df) {
# Sumariza a taxa de sobreviventes por categoria da variável em análise
tgc <- Rmisc::summarySE(df, measurevar = resp, groupvars = c(var))
maxN <- max(tgc$N)
# Gráfico de barras
p <- ggplot(tgc) +
geom_bar(aes(x = tgc[,var],
y = max(tgc[,resp])*N/maxN,
fill = as.factor(tgc[,var])),
position = "identity", stat = "identity",
alpha = 0.5) +
scale_fill_viridis_d(direction = -1, begin = .85, end = .95)
# Gráfico de linhas
p <- p +
geom_line(aes(x = tgc[,var], y = tgc[,resp]), colour = '1', group = '1') +
geom_point(aes(x = tgc[,var], y = tgc[,resp] ), colour = '1', group = '1') +
geom_errorbar(aes(x = tgc[,var],
y = tgc[,resp],
ymin = tgc[,resp] + qnorm(.025)*se,
ymax = tgc[,resp] + qnorm(.975)*se, colour = '1'), width = .5) +
#geom_point(aes(x = tgc[,var], y = tgc[,resp] - tgc[,ep]*qnorm(.975)), colour = '1', group = '1') +
scale_color_viridis_d(direction = -1, begin = 0, end = .25)
# Ajuste dos eixos
p <- p +
theme(panel.background = element_rect(fill = "white", colour = "grey", linetype = "solid"),
panel.grid.major = element_line(size = 0.15, linetype = 'solid', colour = "grey"),
axis.text = element_text(size = 14),  # Tamanho da fonte dos números dos eixos
axis.title = element_text(size = 16),  # Tamanho da fonte dos títulos dos eixos
legend.position = "none") +
xlab(var) + ylab("Barras")
p <- p +
scale_y_continuous(sec.axis = sec_axis(~ . *maxN/max(tgc[,resp]), name = "Frequencia", labels = scales::number)) +
ylab(resp) +
# Limite do eixo vertical esquerdo
coord_cartesian(ylim = c(min(tgc[,resp]) - 0.02, max(tgc[,resp]) + 0.02))
return(p)
}
#####
# Gerando os dados
# x é uma sequencia de valores entre 0 e 1
set.seed(2360873)
x <- seq(0,1, length.out=1000)
# y segue uma relação quadrática
a <- 0
b <- 10
c <- -10
y <- a + b*x + c*x**2 + rnorm(length(x), mean=0, sd=.1)
df <- data.frame(x, y)
p0 <- ggplot(df, aes(x,y)) +
geom_point(aes(colour='Observado')) +
scale_color_viridis(discrete=TRUE, begin=0, end=.85, name = "Valor") +
theme(legend.position="bottom",
legend.spacing.x = unit(0, 'cm'))
p0
########################
# Construindo a árvore #
tree <- rpart(y~x,
data=df,
control=rpart.control(maxdepth = 2, cp=0))
# Plotando a árvore
paleta = scales::viridis_pal(begin=.75, end=1)(20)
rpart.plot::rpart.plot(tree,
box.palette = paleta) # Paleta de cores
# Valores preditos
df['p'] = predict(tree, df)
df$p %>% tail # investigar a previsão
df['r'] = df$y - df$p
# Valores esperados e observados
boost0_O_vs_E <- ggplot(df, aes(x,y)) +
geom_point(alpha=.7, size=.5, aes(colour='Observado')) +
geom_path(aes(x,p, colour='Esperado')) + #Ploting
scale_color_viridis(discrete=TRUE, begin=0, end=.8, name = "Dado: ") +
theme_bw() +
theme(legend.position="bottom") +
# guides(colour = guide_legend(label.position = "bottom")) +
labs(title="Valores observados vs esperados") +
scale_y_continuous(name= "y") +
scale_x_continuous(name= "x")
